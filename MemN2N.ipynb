{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MemN2N.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tjsiledar/Machine-Learning/blob/master/MemN2N.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBjopz9pe2Gb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#libraries to download data and preprocess it.\n",
        "\n",
        "import re\n",
        "import tarfile\n",
        "import numpy as np\n",
        "from functools import reduce\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMM4HjqxgAyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Function to create tokens of a sentence\n",
        "\n",
        "Returns a list of tokens.\n",
        "'''\n",
        "\n",
        "def tokenize(sentence):\n",
        "  return [x.strip() for x in re.split('(\\W+)?', sentence) if x.strip()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czi-Aev3jcRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Function to create tuples of each episode\n",
        "'''\n",
        "\n",
        "def parse_episodes(lines):\n",
        "  \n",
        "  data = []\n",
        "  story = []\n",
        "  \n",
        "  for line in lines:\n",
        "    line = line.decode('utf-8').strip()\n",
        "    nid, line = line.split(' ', 1)\n",
        "    nid = int(nid)\n",
        "    \n",
        "    if nid==1:\n",
        "      story = []\n",
        "    \n",
        "    if '\\t' in line:\n",
        "      q, a, support_id = line.split('\\t')\n",
        "      q = tokenize(q)\n",
        "      substory = [x for x in story if x]\n",
        "      \n",
        "      #add substory question and answer as a tuple to the data list\n",
        "      \n",
        "      data.append((substory,q,a))\n",
        "      story.append('')\n",
        "    else:\n",
        "      sentence = tokenize(line)\n",
        "      story.append(sentence)\n",
        "      \n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u19S-RAjm8pF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Function to create a list of all episodes from the file\n",
        "'''\n",
        "\n",
        "def get_episodes(file):\n",
        "  data = parse_episodes(file.readlines())\n",
        "  flatten = lambda data: reduce(lambda x,y: x+y, data)\n",
        "  data = [(flatten(story), question, answer) for story, question, answer in data]\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDS7q88qoAc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Function to vectorize episodes\n",
        "'''\n",
        "\n",
        "def vectorize(data, word_idx, story_maxlen, query_maxlen):\n",
        "  stories, queries, answers = [], [], []\n",
        "  \n",
        "  for story, query, answer in data:\n",
        "    stories.append([word_idx[w] for w in story])\n",
        "    queries.append([word_idx[w] for w in query])\n",
        "    y = np.zeros(len(word_idx)+1)\n",
        "    y[word_idx[answer]]=1\n",
        "    answers.append(y)\n",
        "    \n",
        "  return (pad_sequences(stories, maxlen=story_maxlen), pad_sequences(queries, maxlen=query_maxlen), np.array(answers))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoSFG0XFfjW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#downloading the dataset\n",
        "\n",
        "path = get_file('babi-tasks-v1-2.tar.gz', origin='https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz')\n",
        "file = tarfile.open(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGzizQhhow05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = {\n",
        "    \n",
        "    'single_supporting_fact_10k' : 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt',\n",
        "    'two_supporting_fact_10k' : 'tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt',\n",
        "}\n",
        "\n",
        "current_dataset = 'single_supporting_fact_10k'\n",
        "\n",
        "dataset = dataset[current_dataset]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isoMK3BuprA1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9c1bcfa6-9915-4127-fe11-466a2fe9540b"
      },
      "source": [
        "#Extracting train and test datasets\n",
        "\n",
        "train_set = get_episodes(file.extractfile(dataset.format('train')))\n",
        "test_set = get_episodes(file.extractfile(dataset.format('test')))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
            "  return _compile(pattern, flags).split(string, maxsplit)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX5ynx3fsBEq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "a33b8f24-2548-4f84-ffc0-c367bb888f7d"
      },
      "source": [
        "#checking our sets\n",
        "\n",
        "print(len(train_set))\n",
        "print(len(test_set))\n",
        "\n",
        "train_set[0]"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n",
            "1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Mary',\n",
              "  'moved',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bathroom',\n",
              "  '.',\n",
              "  'John',\n",
              "  'went',\n",
              "  'to',\n",
              "  'the',\n",
              "  'hallway',\n",
              "  '.'],\n",
              " ['Where', 'is', 'Mary', '?'],\n",
              " 'bathroom')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSIWeIBVxdxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating a vocabulary from our sentences\n",
        "\n",
        "vocab = set()\n",
        "\n",
        "for story, query, answer in train_set + test_set:\n",
        "  vocab |= set(story + query + [answer])\n",
        "vocab = sorted(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYpsCTW0sfok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#as 0 is reserved for padding\n",
        "\n",
        "vocab_size = len(vocab) + 1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaJ80yncymVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculating the maximum length of story and query\n",
        "\n",
        "story_maxlen = max(map(len, (x for x,_,_ in train_set + test_set)))\n",
        "query_maxlen = max(map(len, (x for _,x,_ in train_set + test_set)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-3SkRKi1ZTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating word to index dictionary\n",
        "\n",
        "word_idx = dict((c,i+1) for i,c in enumerate(vocab))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAvI-jEs2Lc3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "84d24d1d-5f3f-4a9d-c845-9bc5c3314703"
      },
      "source": [
        "print(word_idx)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'.': 1, '?': 2, 'Daniel': 3, 'John': 4, 'Mary': 5, 'Sandra': 6, 'Where': 7, 'back': 8, 'bathroom': 9, 'bedroom': 10, 'garden': 11, 'hallway': 12, 'is': 13, 'journeyed': 14, 'kitchen': 15, 'moved': 16, 'office': 17, 'the': 18, 'to': 19, 'travelled': 20, 'went': 21}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs65UtGU2M8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorizing story, query and answer using vocab\n",
        "\n",
        "stories_train, queries_train, answers_train = vectorize(train_set, word_idx, story_maxlen, query_maxlen)\n",
        "stories_test, queries_test, answers_test = vectorize(test_set, word_idx, story_maxlen, query_maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXK7_UfT3Fsp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "16a7c6be-beac-452c-da99-f66f788b1a72"
      },
      "source": [
        "stories_train[0]"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  5, 16, 19, 18,  9,  1,  4, 21, 19, 18, 12,  1],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGzeYo2k3XDE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "316332e4-86e0-4044-e435-378dbb04e5a2"
      },
      "source": [
        "queries_train[0]"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7, 13,  5,  2], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxXtjcyI3Z8e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dea8dd89-2d58-406e-c4ac-44b6372da92f"
      },
      "source": [
        "answers_train[0,:]"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RU0TpxNG7v5R",
        "colab_type": "text"
      },
      "source": [
        "Lets start buliding our End to End model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf2kql1q3eZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import IPython\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        " \n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Permute, dot, add, concatenate\n",
        "from keras.layers import LSTM, Dense, Dropout, Input, Activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej9R4I_a81HI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of epochs to run\n",
        "train_epochs = 100\n",
        "# Training batch size\n",
        "batch_size = 32\n",
        "# Hidden embedding size\n",
        "embed_size = 50\n",
        "# number of nodes in LSTM layer\n",
        "lstm_size = 64\n",
        "# dropout rate\n",
        "dropout_rate = 0.30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTlxUqbv83HF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#placeholders\n",
        "\n",
        "input_sequence = Input((story_maxlen,))\n",
        "question = Input((query_maxlen,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff4Zp9j0ZsnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#encoders\n",
        "\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size, output_dim=embed_size))\n",
        "input_encoder_m.add(Dropout(dropout_rate))\n",
        "\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size, output_dim=query_maxlen))\n",
        "input_encoder_c.add(Dropout(dropout_rate))\n",
        "\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size, output_dim=embed_size, input_length=query_maxlen))\n",
        "question_encoder.add(Dropout(dropout_rate))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpRBQcg6Zu-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx-t3ekUgK_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compute match between first input vector and question vector\n",
        "\n",
        "match = dot([input_encoded_m, question_encoded], axes=-1, normalize=False)\n",
        "match = Activation('softmax')(match)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AwrvXQWg0Xc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add match to the second input vector\n",
        "\n",
        "res = add([match, input_encoded_c])\n",
        "res = Permute((2,1))(res)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_qO-tUVlVL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# concatenate the response vector with question vector\n",
        "\n",
        "answer = concatenate([res, question_encoded])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92o4rVzjlqlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answer = LSTM(lstm_size)(answer)\n",
        "answer = Dropout(dropout_rate)(answer)\n",
        "answer = Dense(vocab_size)(answer)\n",
        "answer = Activation('softmax')(answer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yKMu4HamJcB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "c12d0a07-2f16-4a93-c70e-2989daa624ae"
      },
      "source": [
        "# building the model\n",
        "\n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0728 12:42:39.603384 140667283019648 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0728 12:42:39.632448 140667283019648 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndmRUKKVmq_c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "095aaeae-c0b4-4d70-f998-5cd67841392e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 68)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 4)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_5 (Sequential)       multiple             1100        input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_7 (Sequential)       (None, 4, 50)        1100        input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot_2 (Dot)                     (None, 68, 4)        0           sequential_5[1][0]               \n",
            "                                                                 sequential_7[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 68, 4)        0           dot_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "sequential_6 (Sequential)       multiple             88          input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 68, 4)        0           activation_2[0][0]               \n",
            "                                                                 sequential_6[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute_1 (Permute)             (None, 4, 68)        0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 4, 118)       0           permute_1[0][0]                  \n",
            "                                                                 sequential_7[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 64)           46848       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 64)           0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 22)           1430        dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 22)           0           dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 50,566\n",
            "Trainable params: 50,566\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHdH4e8umuIG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a89c16f1-5e7b-40bc-c5e3-b0b13b71fb0d"
      },
      "source": [
        "model.fit([stories_train, queries_train], answers_train, batch_size, train_epochs, validation_data = ([stories_test, queries_test], answers_test))"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0728 12:45:44.216058 140667283019648 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/100\n",
            "10000/10000 [==============================] - 5s 536us/step - loss: 1.8887 - acc: 0.1704 - val_loss: 1.8136 - val_acc: 0.1490\n",
            "Epoch 2/100\n",
            "10000/10000 [==============================] - 4s 354us/step - loss: 1.7185 - acc: 0.2393 - val_loss: 1.6468 - val_acc: 0.2930\n",
            "Epoch 3/100\n",
            "10000/10000 [==============================] - 4s 354us/step - loss: 1.6470 - acc: 0.2835 - val_loss: 1.5909 - val_acc: 0.3770\n",
            "Epoch 4/100\n",
            "10000/10000 [==============================] - 4s 355us/step - loss: 1.5326 - acc: 0.3785 - val_loss: 1.4854 - val_acc: 0.4020\n",
            "Epoch 5/100\n",
            "10000/10000 [==============================] - 4s 352us/step - loss: 1.4799 - acc: 0.3985 - val_loss: 1.4270 - val_acc: 0.4210\n",
            "Epoch 6/100\n",
            "10000/10000 [==============================] - 4s 354us/step - loss: 1.4109 - acc: 0.4354 - val_loss: 1.3593 - val_acc: 0.4730\n",
            "Epoch 7/100\n",
            "10000/10000 [==============================] - 4s 353us/step - loss: 1.3773 - acc: 0.4522 - val_loss: 1.3588 - val_acc: 0.4710\n",
            "Epoch 8/100\n",
            "10000/10000 [==============================] - 4s 352us/step - loss: 1.3634 - acc: 0.4620 - val_loss: 1.3509 - val_acc: 0.4830\n",
            "Epoch 9/100\n",
            "10000/10000 [==============================] - 4s 355us/step - loss: 1.3548 - acc: 0.4694 - val_loss: 1.3175 - val_acc: 0.4960\n",
            "Epoch 10/100\n",
            "10000/10000 [==============================] - 4s 352us/step - loss: 1.3252 - acc: 0.4863 - val_loss: 1.2859 - val_acc: 0.5150\n",
            "Epoch 11/100\n",
            "10000/10000 [==============================] - 4s 351us/step - loss: 1.2945 - acc: 0.4990 - val_loss: 1.2597 - val_acc: 0.5280\n",
            "Epoch 12/100\n",
            "10000/10000 [==============================] - 4s 355us/step - loss: 1.2601 - acc: 0.5063 - val_loss: 1.2123 - val_acc: 0.5190\n",
            "Epoch 13/100\n",
            "10000/10000 [==============================] - 4s 355us/step - loss: 1.2389 - acc: 0.5053 - val_loss: 1.2017 - val_acc: 0.5170\n",
            "Epoch 14/100\n",
            "10000/10000 [==============================] - 4s 357us/step - loss: 1.2032 - acc: 0.5112 - val_loss: 1.2093 - val_acc: 0.5100\n",
            "Epoch 15/100\n",
            "10000/10000 [==============================] - 4s 357us/step - loss: 1.1968 - acc: 0.5170 - val_loss: 1.1721 - val_acc: 0.5200\n",
            "Epoch 16/100\n",
            "10000/10000 [==============================] - 4s 352us/step - loss: 1.1800 - acc: 0.5200 - val_loss: 1.1635 - val_acc: 0.4980\n",
            "Epoch 17/100\n",
            "10000/10000 [==============================] - 4s 351us/step - loss: 1.1598 - acc: 0.5194 - val_loss: 1.1646 - val_acc: 0.5190\n",
            "Epoch 18/100\n",
            "10000/10000 [==============================] - 4s 351us/step - loss: 1.1494 - acc: 0.5207 - val_loss: 1.1705 - val_acc: 0.5140\n",
            "Epoch 19/100\n",
            "10000/10000 [==============================] - 4s 352us/step - loss: 1.1443 - acc: 0.5303 - val_loss: 1.1714 - val_acc: 0.4950\n",
            "Epoch 20/100\n",
            "10000/10000 [==============================] - 3s 348us/step - loss: 1.1406 - acc: 0.5263 - val_loss: 1.1475 - val_acc: 0.5180\n",
            "Epoch 21/100\n",
            "10000/10000 [==============================] - 4s 355us/step - loss: 1.1387 - acc: 0.5225 - val_loss: 1.1497 - val_acc: 0.5090\n",
            "Epoch 22/100\n",
            "10000/10000 [==============================] - 4s 352us/step - loss: 1.1281 - acc: 0.5260 - val_loss: 1.1496 - val_acc: 0.5050\n",
            "Epoch 23/100\n",
            "10000/10000 [==============================] - 3s 350us/step - loss: 1.1239 - acc: 0.5296 - val_loss: 1.1482 - val_acc: 0.5210\n",
            "Epoch 24/100\n",
            "10000/10000 [==============================] - 4s 353us/step - loss: 1.1194 - acc: 0.5342 - val_loss: 1.1585 - val_acc: 0.5220\n",
            "Epoch 25/100\n",
            "10000/10000 [==============================] - 3s 349us/step - loss: 1.1136 - acc: 0.5300 - val_loss: 1.1462 - val_acc: 0.5020\n",
            "Epoch 26/100\n",
            "10000/10000 [==============================] - 4s 360us/step - loss: 1.1001 - acc: 0.5330 - val_loss: 1.1404 - val_acc: 0.4950\n",
            "Epoch 27/100\n",
            "10000/10000 [==============================] - 4s 362us/step - loss: 1.1014 - acc: 0.5297 - val_loss: 1.1582 - val_acc: 0.5130\n",
            "Epoch 28/100\n",
            "10000/10000 [==============================] - 4s 363us/step - loss: 1.0882 - acc: 0.5394 - val_loss: 1.1537 - val_acc: 0.5140\n",
            "Epoch 29/100\n",
            "10000/10000 [==============================] - 4s 356us/step - loss: 1.0834 - acc: 0.5374 - val_loss: 1.1649 - val_acc: 0.5120\n",
            "Epoch 30/100\n",
            "10000/10000 [==============================] - 4s 353us/step - loss: 1.0814 - acc: 0.5405 - val_loss: 1.1904 - val_acc: 0.5030\n",
            "Epoch 31/100\n",
            "10000/10000 [==============================] - 3s 348us/step - loss: 1.0725 - acc: 0.5480 - val_loss: 1.1777 - val_acc: 0.5110\n",
            "Epoch 32/100\n",
            "10000/10000 [==============================] - 3s 350us/step - loss: 1.0739 - acc: 0.5460 - val_loss: 1.1767 - val_acc: 0.5130\n",
            "Epoch 33/100\n",
            "10000/10000 [==============================] - 4s 352us/step - loss: 1.0640 - acc: 0.5505 - val_loss: 1.1728 - val_acc: 0.5240\n",
            "Epoch 34/100\n",
            "10000/10000 [==============================] - 3s 348us/step - loss: 1.0526 - acc: 0.5579 - val_loss: 1.1572 - val_acc: 0.5060\n",
            "Epoch 35/100\n",
            "10000/10000 [==============================] - 4s 352us/step - loss: 1.0497 - acc: 0.5550 - val_loss: 1.1549 - val_acc: 0.5190\n",
            "Epoch 36/100\n",
            "10000/10000 [==============================] - 4s 355us/step - loss: 1.0354 - acc: 0.5595 - val_loss: 1.1637 - val_acc: 0.5360\n",
            "Epoch 37/100\n",
            "10000/10000 [==============================] - 4s 353us/step - loss: 1.0275 - acc: 0.5733 - val_loss: 1.1262 - val_acc: 0.5450\n",
            "Epoch 38/100\n",
            "10000/10000 [==============================] - 4s 354us/step - loss: 0.9752 - acc: 0.6013 - val_loss: 1.0257 - val_acc: 0.6180\n",
            "Epoch 39/100\n",
            "10000/10000 [==============================] - 4s 351us/step - loss: 0.8247 - acc: 0.6876 - val_loss: 0.7942 - val_acc: 0.7210\n",
            "Epoch 40/100\n",
            "10000/10000 [==============================] - 3s 349us/step - loss: 0.6717 - acc: 0.7529 - val_loss: 0.6898 - val_acc: 0.7440\n",
            "Epoch 41/100\n",
            "10000/10000 [==============================] - 3s 348us/step - loss: 0.6106 - acc: 0.7735 - val_loss: 0.6764 - val_acc: 0.7440\n",
            "Epoch 42/100\n",
            "10000/10000 [==============================] - 3s 349us/step - loss: 0.5609 - acc: 0.7861 - val_loss: 0.5981 - val_acc: 0.7560\n",
            "Epoch 43/100\n",
            "10000/10000 [==============================] - 3s 349us/step - loss: 0.5152 - acc: 0.8029 - val_loss: 0.5556 - val_acc: 0.7750\n",
            "Epoch 44/100\n",
            "10000/10000 [==============================] - 3s 348us/step - loss: 0.4669 - acc: 0.8203 - val_loss: 0.5305 - val_acc: 0.7770\n",
            "Epoch 45/100\n",
            "10000/10000 [==============================] - 4s 353us/step - loss: 0.4316 - acc: 0.8315 - val_loss: 0.4791 - val_acc: 0.8020\n",
            "Epoch 46/100\n",
            "10000/10000 [==============================] - 3s 349us/step - loss: 0.3909 - acc: 0.8516 - val_loss: 0.4315 - val_acc: 0.8280\n",
            "Epoch 47/100\n",
            "10000/10000 [==============================] - 3s 350us/step - loss: 0.3549 - acc: 0.8678 - val_loss: 0.4079 - val_acc: 0.8470\n",
            "Epoch 48/100\n",
            "10000/10000 [==============================] - 4s 351us/step - loss: 0.3330 - acc: 0.8712 - val_loss: 0.3984 - val_acc: 0.8530\n",
            "Epoch 49/100\n",
            "10000/10000 [==============================] - 3s 349us/step - loss: 0.3181 - acc: 0.8814 - val_loss: 0.3637 - val_acc: 0.8600\n",
            "Epoch 50/100\n",
            "10000/10000 [==============================] - 3s 349us/step - loss: 0.2992 - acc: 0.8888 - val_loss: 0.3528 - val_acc: 0.8700\n",
            "Epoch 51/100\n",
            "10000/10000 [==============================] - 4s 351us/step - loss: 0.2744 - acc: 0.8983 - val_loss: 0.3354 - val_acc: 0.8770\n",
            "Epoch 52/100\n",
            "10000/10000 [==============================] - 3s 349us/step - loss: 0.2686 - acc: 0.9004 - val_loss: 0.3343 - val_acc: 0.8870\n",
            "Epoch 53/100\n",
            "10000/10000 [==============================] - 3s 349us/step - loss: 0.2537 - acc: 0.9056 - val_loss: 0.3037 - val_acc: 0.8850\n",
            "Epoch 54/100\n",
            "10000/10000 [==============================] - 4s 350us/step - loss: 0.2413 - acc: 0.9127 - val_loss: 0.2923 - val_acc: 0.8930\n",
            "Epoch 55/100\n",
            "10000/10000 [==============================] - 4s 352us/step - loss: 0.2171 - acc: 0.9210 - val_loss: 0.2748 - val_acc: 0.9070\n",
            "Epoch 56/100\n",
            "10000/10000 [==============================] - 3s 348us/step - loss: 0.2044 - acc: 0.9257 - val_loss: 0.2715 - val_acc: 0.9050\n",
            "Epoch 57/100\n",
            "10000/10000 [==============================] - 4s 350us/step - loss: 0.1912 - acc: 0.9282 - val_loss: 0.2526 - val_acc: 0.9170\n",
            "Epoch 58/100\n",
            "10000/10000 [==============================] - 3s 349us/step - loss: 0.1833 - acc: 0.9328 - val_loss: 0.2491 - val_acc: 0.9150\n",
            "Epoch 59/100\n",
            "10000/10000 [==============================] - 4s 352us/step - loss: 0.1696 - acc: 0.9399 - val_loss: 0.2235 - val_acc: 0.9240\n",
            "Epoch 60/100\n",
            "10000/10000 [==============================] - 4s 357us/step - loss: 0.1540 - acc: 0.9446 - val_loss: 0.2191 - val_acc: 0.9290\n",
            "Epoch 61/100\n",
            "10000/10000 [==============================] - 4s 352us/step - loss: 0.1481 - acc: 0.9472 - val_loss: 0.2162 - val_acc: 0.9230\n",
            "Epoch 62/100\n",
            "10000/10000 [==============================] - 4s 354us/step - loss: 0.1403 - acc: 0.9519 - val_loss: 0.2236 - val_acc: 0.9320\n",
            "Epoch 63/100\n",
            "10000/10000 [==============================] - 4s 357us/step - loss: 0.1327 - acc: 0.9561 - val_loss: 0.2010 - val_acc: 0.9330\n",
            "Epoch 64/100\n",
            "10000/10000 [==============================] - 3s 347us/step - loss: 0.1317 - acc: 0.9511 - val_loss: 0.1906 - val_acc: 0.9330\n",
            "Epoch 65/100\n",
            "10000/10000 [==============================] - 3s 349us/step - loss: 0.1218 - acc: 0.9574 - val_loss: 0.2018 - val_acc: 0.9340\n",
            "Epoch 66/100\n",
            "10000/10000 [==============================] - 4s 351us/step - loss: 0.1152 - acc: 0.9604 - val_loss: 0.2133 - val_acc: 0.9310\n",
            "Epoch 67/100\n",
            "10000/10000 [==============================] - 3s 349us/step - loss: 0.1121 - acc: 0.9621 - val_loss: 0.2031 - val_acc: 0.9370\n",
            "Epoch 68/100\n",
            "10000/10000 [==============================] - 3s 348us/step - loss: 0.1137 - acc: 0.9623 - val_loss: 0.1968 - val_acc: 0.9350\n",
            "Epoch 69/100\n",
            "10000/10000 [==============================] - 4s 351us/step - loss: 0.1031 - acc: 0.9618 - val_loss: 0.2012 - val_acc: 0.9350\n",
            "Epoch 70/100\n",
            "10000/10000 [==============================] - 3s 349us/step - loss: 0.1030 - acc: 0.9660 - val_loss: 0.1687 - val_acc: 0.9470\n",
            "Epoch 71/100\n",
            "10000/10000 [==============================] - 3s 347us/step - loss: 0.0963 - acc: 0.9660 - val_loss: 0.1638 - val_acc: 0.9400\n",
            "Epoch 72/100\n",
            "10000/10000 [==============================] - 3s 347us/step - loss: 0.1077 - acc: 0.9647 - val_loss: 0.1614 - val_acc: 0.9450\n",
            "Epoch 73/100\n",
            "10000/10000 [==============================] - 4s 350us/step - loss: 0.0891 - acc: 0.9714 - val_loss: 0.1647 - val_acc: 0.9440\n",
            "Epoch 74/100\n",
            "10000/10000 [==============================] - 3s 346us/step - loss: 0.0857 - acc: 0.9718 - val_loss: 0.1626 - val_acc: 0.9450\n",
            "Epoch 75/100\n",
            "10000/10000 [==============================] - 3s 345us/step - loss: 0.0799 - acc: 0.9733 - val_loss: 0.1687 - val_acc: 0.9530\n",
            "Epoch 76/100\n",
            "10000/10000 [==============================] - 3s 348us/step - loss: 0.0809 - acc: 0.9727 - val_loss: 0.1776 - val_acc: 0.9440\n",
            "Epoch 77/100\n",
            "10000/10000 [==============================] - 3s 348us/step - loss: 0.0853 - acc: 0.9732 - val_loss: 0.1590 - val_acc: 0.9510\n",
            "Epoch 78/100\n",
            "10000/10000 [==============================] - 3s 346us/step - loss: 0.0789 - acc: 0.9752 - val_loss: 0.1531 - val_acc: 0.9500\n",
            "Epoch 79/100\n",
            "10000/10000 [==============================] - 3s 347us/step - loss: 0.0720 - acc: 0.9764 - val_loss: 0.1787 - val_acc: 0.9460\n",
            "Epoch 80/100\n",
            "10000/10000 [==============================] - 3s 347us/step - loss: 0.0753 - acc: 0.9759 - val_loss: 0.1970 - val_acc: 0.9420\n",
            "Epoch 81/100\n",
            "10000/10000 [==============================] - 3s 345us/step - loss: 0.0721 - acc: 0.9753 - val_loss: 0.1565 - val_acc: 0.9530\n",
            "Epoch 82/100\n",
            "10000/10000 [==============================] - 4s 353us/step - loss: 0.0667 - acc: 0.9774 - val_loss: 0.1530 - val_acc: 0.9520\n",
            "Epoch 83/100\n",
            "10000/10000 [==============================] - 4s 350us/step - loss: 0.0619 - acc: 0.9786 - val_loss: 0.1556 - val_acc: 0.9490\n",
            "Epoch 84/100\n",
            "10000/10000 [==============================] - 3s 347us/step - loss: 0.0655 - acc: 0.9786 - val_loss: 0.1609 - val_acc: 0.9580\n",
            "Epoch 85/100\n",
            "10000/10000 [==============================] - 3s 346us/step - loss: 0.0559 - acc: 0.9814 - val_loss: 0.1658 - val_acc: 0.9520\n",
            "Epoch 86/100\n",
            "10000/10000 [==============================] - 3s 345us/step - loss: 0.0589 - acc: 0.9813 - val_loss: 0.1640 - val_acc: 0.9510\n",
            "Epoch 87/100\n",
            "10000/10000 [==============================] - 3s 348us/step - loss: 0.0536 - acc: 0.9828 - val_loss: 0.1607 - val_acc: 0.9540\n",
            "Epoch 88/100\n",
            "10000/10000 [==============================] - 3s 346us/step - loss: 0.0557 - acc: 0.9815 - val_loss: 0.1634 - val_acc: 0.9550\n",
            "Epoch 89/100\n",
            "10000/10000 [==============================] - 3s 346us/step - loss: 0.0612 - acc: 0.9790 - val_loss: 0.1615 - val_acc: 0.9550\n",
            "Epoch 90/100\n",
            "10000/10000 [==============================] - 3s 348us/step - loss: 0.0475 - acc: 0.9861 - val_loss: 0.1795 - val_acc: 0.9480\n",
            "Epoch 91/100\n",
            "10000/10000 [==============================] - 3s 345us/step - loss: 0.0456 - acc: 0.9844 - val_loss: 0.1667 - val_acc: 0.9530\n",
            "Epoch 92/100\n",
            "10000/10000 [==============================] - 3s 343us/step - loss: 0.0472 - acc: 0.9834 - val_loss: 0.1496 - val_acc: 0.9610\n",
            "Epoch 93/100\n",
            "10000/10000 [==============================] - 3s 345us/step - loss: 0.0449 - acc: 0.9869 - val_loss: 0.1662 - val_acc: 0.9510\n",
            "Epoch 94/100\n",
            "10000/10000 [==============================] - 3s 345us/step - loss: 0.0466 - acc: 0.9856 - val_loss: 0.1776 - val_acc: 0.9580\n",
            "Epoch 95/100\n",
            "10000/10000 [==============================] - 3s 347us/step - loss: 0.0562 - acc: 0.9836 - val_loss: 0.1549 - val_acc: 0.9570\n",
            "Epoch 96/100\n",
            "10000/10000 [==============================] - 3s 347us/step - loss: 0.0418 - acc: 0.9870 - val_loss: 0.1864 - val_acc: 0.9460\n",
            "Epoch 97/100\n",
            "10000/10000 [==============================] - 3s 344us/step - loss: 0.0441 - acc: 0.9866 - val_loss: 0.1662 - val_acc: 0.9570\n",
            "Epoch 98/100\n",
            "10000/10000 [==============================] - 3s 349us/step - loss: 0.0413 - acc: 0.9874 - val_loss: 0.1719 - val_acc: 0.9570\n",
            "Epoch 99/100\n",
            "10000/10000 [==============================] - 3s 348us/step - loss: 0.0431 - acc: 0.9869 - val_loss: 0.1514 - val_acc: 0.9590\n",
            "Epoch 100/100\n",
            "10000/10000 [==============================] - 3s 346us/step - loss: 0.0390 - acc: 0.9888 - val_loss: 0.1976 - val_acc: 0.9540\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fef5abb0cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VgDylYNnYCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}